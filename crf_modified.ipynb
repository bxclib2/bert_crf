{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bxclib2/bert_crf/blob/master/crf_modified.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JdbcCEnYFTd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CRF(nn.Module):    \n",
        "        '''\n",
        "        This class implemented a conditional random field. This class heavily adapted the code for pytorch-crf. Github: https://github.com/kmkurn/pytorch-crf/ \n",
        "        This implementation enables the [mask] to be within a sentence, which is useful for the model who uses word-piece model like BERT. \n",
        "        batch_first is default true in this implemetation.\n",
        "        Args:\n",
        "            tags_num: Number of tags.\n",
        "            batch_first: Whether the first dimension corresponds to the size of a minibatch.\n",
        "        '''\n",
        "    def __init__(self,tags_num ,batch_first = True):\n",
        "        self.init_range = 0.1\n",
        "        if tags_num <= 0:\n",
        "            raise ValueError('The tags_num should be strictly positive %s' % tags_num)\n",
        "        super(CRF,self).__init__()\n",
        "        self.tags_num = tags_num\n",
        "        self.__transitions = nn.Parameter(torch.empty(tags_num,tags_num))\n",
        "        self.register_buffer('last_tag', torch.ones(self.batch_size).long())\n",
        "        self.__init_transitions = nn.Parameter(torch.empty(tags_num))\n",
        "        self.__stop_transitions = nn.Parameter(torch.empty(tags_num))\n",
        "        \n",
        "        nn.init.uniform_(self.init_transitions, -1.0*self.init_range, self.init_range)\n",
        "        nn.init.uniform_(self.stop_transitions, -1.0*self.init_range, self.init_range)\n",
        "        nn.init.uniform_(self.transitions, -1.0*self.init_range, self.init_range)               \n",
        "    def forward(self, batch_feat, batch_tag, batch_mask, reduction):\n",
        "        \"\"\"Compute the conditional log likelihood of a sequence of tags given emission scores. This part is usually used as a loss function to optimize.\n",
        "        Args:\n",
        "            batch_feat (torch.Tensor): Input feature from the previous layer.\n",
        "                ``(batch_size, seq_length, num_tags)`` if ``batch_first`` is ``True``,\n",
        "                ``(seq_length, batch_size, num_tags)`` if ``batch_first`` is ``False``.\n",
        "\n",
        "            batch_tag (torch.LongTensor): Sequence of tags tensor of size\n",
        "                ``(batch_size, seq_length)`` if ``batch_first`` is ``True``,\n",
        "                ``(seq_length ,batch_size)`` if ``batch_first`` is ``False``.\n",
        "            batch_mask (torch.ByteTensor): Mask tensor of the same size with batch_tag.\n",
        "            reduction: Specifies  the reduction to apply to the output:\n",
        "                ``none|sum|mean|token_mean``. ``none``: no reduction will be applied.\n",
        "                ``sum``: the output will be summed over batches. ``mean``: the output will be\n",
        "                averaged over batches. ``token_mean``: the output will be averaged over tokens.\n",
        "        Returns:\n",
        "            `torch.Tensor`: The log likelihood. This will have size ``(batch_size,)`` if\n",
        "            reduction is ``none``, ``()`` otherwise.\n",
        "        \"\"\"\n",
        "        self.check_dimension(batch_feat, batch_tag=batch_tag, batch_mask=batch_mask)\n",
        "        if reduction not in ('none', 'sum', 'mean', 'token_mean'):\n",
        "            raise ValueError('invalid reduction % reduction')\n",
        "        if batch_mask is None:\n",
        "            batch_mask = batch_tag.new_ones(batch_tag.shape, dtype=torch.uint8)\n",
        "\n",
        "        if not self.batch_first:\n",
        "            batch_feat = batch_feat.transpose(0, 1)\n",
        "            batch_tag = batch_tag.transpose(0, 1)\n",
        "            batch_mask = batch_mask.transpose(0, 1)\n",
        "        score = self.score_sentence(batch_feat,batch_tag,batch_mask)\n",
        "        \n",
        "        partition = self.compute_log_partition(batch_feat,batch_mask)\n",
        "        \n",
        "        res =  score - partition\n",
        "        \n",
        "        if reduction == 'none':\n",
        "            return res\n",
        "        if reduction == 'sum':\n",
        "            return res.sum()\n",
        "        if reduction == 'mean':\n",
        "            return res.mean()\n",
        "        of reduction == 'token_mean'\n",
        "           return res.sum() / batch_mask.float().sum()\n",
        "    def score_sentence(self,batch_feat, batch_tag, batch_mask):      \n",
        "        batch_size, seq_length, hidden_dim = batch_feat.shape      \n",
        "        score = self.__init_transitions[batch_tag[:,0]]           \n",
        "        self.last_tag = batch_tag[:,0]   \n",
        "        \n",
        "        for i in range(1,self.seq_length):\n",
        "            # Transition score to next tag, only added if next timestep is valid (mask == 1)\n",
        "            # shape: (batch_size,)\n",
        "            score += batch_feat[torch.arange(batch_size),i,batch_tag[:,i]]*mask[:,i]#.view(-1)\n",
        "            # Emission score for next tag, only added if next timestep is valid (mask == 1)\n",
        "            # shape: (batch_size,)\n",
        "            score += self.__transitions[self.last_tag,batch_tag[:,i]]*mask[:,i]         \n",
        "            self.last_tag = torch.where(mask[:,i].byte(), batch_tag[:,i], self.last_tag)   \n",
        "            \n",
        "        # A trick to find the last non-zero position\n",
        "        seq_end = batch_mask.float() + 0.1/seq_length*torch.arange(seq_length).unsqueeze(0)\n",
        "        seq_end_point = torch.argmax(seq_end,axis = 1)\n",
        "        # shape: (batch_size,)\n",
        "        last_tags = batch_tag[torch.arange(batch_size),seq_end_point]\n",
        "        # shape: (batch_size,)\n",
        "        score += self.__stop_transitions[last_tags]\n",
        "        return score\n",
        "\n",
        "    def compute_log_partition(self,batch_feat,batch_mask):\n",
        "        self.batch_size, self.seq_length, self.hidden_dim = batch_feat.shape\n",
        "        # Start transition score and first emission; score has size of\n",
        "        # (batch_size, num_tags) where for each batch, the j-th column stores\n",
        "        # the score that the first timestep has tag j\n",
        "        # shape: (batch_size, num_tags)\n",
        "        alphas = batch_feat[:,0,:] + self.__init_transitions  \n",
        "        \n",
        "        for i in range(1, self.seq_length): \n",
        "            # Broadcast score for every possible next tag\n",
        "            # shape: (batch_size, num_tags, 1)\n",
        "            alphas = alphas.unsqueeze(2)\n",
        "            # Broadcast emission score for every possible current tag\n",
        "            # shape: (batch_size, 1, num_tags)\n",
        "            e_scores = batch_feat[:, i, :].unsqueeze(1)     \n",
        "            \n",
        "            # Compute the score tensor of size (batch_size, num_tags, num_tags) where\n",
        "            # for each sample, entry at row i and column j stores the sum of scores of all\n",
        "            # possible tag sequences so far that end with transitioning from tag i to tag j\n",
        "            # and emitting\n",
        "            # shape: (batch_size, num_tags, num_tags)\n",
        "            t_scores = self.__transitions[:, :].unsqueeze(0)\n",
        "            scores = e_scores + t_scores + alphas\n",
        "            new_alphas = torch.logsumexp(scores, dim=1) \n",
        "            \n",
        "            # Set score to the next score if this timestep is valid (mask == 1)\n",
        "            # shape: (batch_size, num_tags)\n",
        "            alphas = torch.where(mask[i].unsqueeze(1), new_alphas, alphas.squeeze())\n",
        "            \n",
        "        # End transition score\n",
        "        # shape: (batch_size, num_tags)\n",
        "        score += self.__stop_transitions            \n",
        "        return torch.logsumexp(alphas, dim=1)\n",
        "      \n",
        "    def decode(self, batch_feat, batch_mask):\n",
        "        \"\"\"Find the most likely tag sequence using Viterbi algorithm.\n",
        "        Args:\n",
        "            batch_feat (torch.Tensor): Input feature from the previous layer.\n",
        "                ``(batch_size, seq_length, num_tags)`` if ``batch_first`` is ``True``,\n",
        "                ``(seq_length, batch_size, num_tags)`` if ``batch_first`` is ``False``.\n",
        "            batch_mask (`~torch.ByteTensor`): Mask tensor of size ``(batch_size, seq_length)``\n",
        "                if ``batch_first`` is ``True``, ``(seq_length, batch_size)`` otherwise.\n",
        "        Returns:\n",
        "            List of list containing the best tag sequence for each batch.\n",
        "        \"\"\"\n",
        "        self.check_dimension(batch_feat, batch_mask=batch_mask)\n",
        "        if batch_mask is None:\n",
        "            batch_mask = batch_feat.new_ones(batch_feat.shape[:2], dtype=torch.uint8)\n",
        "\n",
        "        if not self.batch_first:\n",
        "            batch_feat = batch_feat.transpose(0, 1)\n",
        "            batch_mask = batch_mask.transpose(0, 1)\n",
        "\n",
        "        return self.viterbi_decode(batch_feat, batch_mask)\n",
        "     \n",
        "    def viterbi_decode(self,batch_feat,batch_mask):\n",
        "        # Start transition and first emission\n",
        "        # shape: (batch_size, num_tags)\n",
        "        batch_size, seq_length, hidden_dim = batch_feat.shape        \n",
        "        alphas = batch_feat[:,0,:] + self.__init_transitions\n",
        "        \n",
        "        history = []\n",
        "        # score is a tensor of size (batch_size, num_tags) where for every batch,\n",
        "        # value at column j stores the score of the best tag sequence so far that ends\n",
        "        # with tag j\n",
        "        # history saves where the best tags candidate transitioned from; this is used\n",
        "        # when we trace back the best tag sequence\n",
        "\n",
        "        # Viterbi algorithm recursive case: we compute the score of the best tag sequence\n",
        "        # for every possible next tag        \n",
        "        for i in range(1, self.seq_length):  \n",
        "            # Broadcast score for every possible next tag\n",
        "            # shape: (batch_size, num_tags, 1)\n",
        "            alphas = alphas.unsqueeze(2)\n",
        "\n",
        "            # Broadcast emission score for every possible current tag\n",
        "            # shape: (batch_size, 1, num_tags)\n",
        "            e_scores = batch_feat[:, i, :].unsqueeze(1)\n",
        "            \n",
        "            # Compute the score tensor of size (batch_size, num_tags, num_tags) where\n",
        "            # for each sample, entry at row i and column j stores the score of the best\n",
        "            # tag sequence so far that ends with transitioning from tag i to tag j and emitting\n",
        "            # shape: (batch_size, num_tags, num_tags)\n",
        "            t_scores = self.__transitions[:, :].unsqueeze(0)\n",
        "            scores = e_scores + t_scores + alphas\n",
        "\n",
        "            \n",
        "            # Find the maximum score over all possible current tag\n",
        "            # Viterbi step\n",
        "            # shape: (batch_size, num_tags)\n",
        "            new_alphas,idx = torch.max(scores, dim=1)\n",
        "            \n",
        "            # Set score to the next score if this timestep is valid (mask == 1)\n",
        "            # shape: (batch_size, num_tags)\n",
        "            alphas = torch.where(mask[i].unsqueeze(1), new_alphas, alphas.squeeze())\n",
        "            \n",
        "            history.append(idx)\n",
        "            \n",
        "        # End transition score\n",
        "        # shape: (batch_size, num_tags)\n",
        "        alphas += self.__stop_transitions\n",
        "\n",
        "        best_tags_list = []\n",
        "        \n",
        "        # A trick to find the last non-zero position\n",
        "        seq_end = batch_mask.float() + 0.1/seq_length*torch.arange(seq_length).unsqueeze(0)\n",
        "        seq_end_point = torch.argmax(seq_end,axis = 1)\n",
        "\n",
        "        for i in range(self.batch_size):\n",
        "            _, best_last_tag = alphas[seq_end_point].max(dim=0)\n",
        "            best_tags = [best_last_tag.item()]\n",
        "\n",
        "            for p,hist in enumerate(reversed(history[0:seq_end_point[i].item()])): # must start from the right seq_end_point, or it will be a completely different path from another masked start point\n",
        "                  best_last_tag = hist[i][best_tags[-1]]\n",
        "                  best_tags.append(best_last_tag.item())\n",
        "\n",
        "            # Reverse the order because we start from the last timestep\n",
        "            best_tags.reverse()\n",
        "            best_tags_list.append(best_tags)\n",
        "\n",
        "        return torch.LongTensor(best_tags_list).to(batch_feat.device)\n",
        "      \n",
        "    @property   \n",
        "    def transitions(self):  \n",
        "        return self.__transitions  \n",
        "    @transitions.setter   \n",
        "    def transitions(self,transitions):  \n",
        "        transitions = torch.Tensor(transitions)\n",
        "        if transitions.shape != (self.tags_num,self.tags_num):\n",
        "            raise ValueError('The transiton dimension should be %s*%s '% self.transitions.shape          \n",
        "        self.__transitions = transitions \n",
        "    @property   \n",
        "    def init_transitions(self):  \n",
        "        return self.__init_transitions \n",
        "    @init_transitions.setter   \n",
        "    def init_transitions(self,init_transitions):  \n",
        "        init_transitions = torch.Tensor(init_transitions)\n",
        "        if init_transitions.shape != self.tags_num:\n",
        "            raise ValueError('The init_transitions dimension should be %s '% self.init_transitions.shape          \n",
        "        self.__init_transitions = init_transitions \n",
        "    @property   \n",
        "    def stop_transitions(self):  \n",
        "        return self.__transitions  \n",
        "    @stop_transitions.setter   \n",
        "    def stop_transitions(self,transitions):  \n",
        "        stop_transitions = torch.Tensor(stop_transitions)\n",
        "        if stop_transitions.shape != self.tags_num:\n",
        "            raise ValueError('The stop_transiton dimension should be %s*%s '% self.stop_transitions.shape          \n",
        "        self.__stop_transitions = stop_transitions    \n",
        "    def __repr__(self):\n",
        "        return \"CRF with %s tags\" % self.tags_num\n",
        "                             \n",
        "    def check_dimension(self, batch_feat, batch_tag = None,batch_mask = None):\n",
        "        if batch_feat.dim() != 3:\n",
        "            raise ValueError(\"batch_feat should be a 3 dimension tensor, got %s\" % batch_feat.dim())\n",
        "        if batch_feat.size(2) != self.num_tags:\n",
        "            raise ValueError(\"Expected last dimension of batch_feat equals num_tags, but got %s and %s respectively.\" % (self.batch_feat.size(2), self.num_tags))\n",
        "        if batch_tag is not None:\n",
        "            if batch_feat.shape[:2] != batch_tag.shape:\n",
        "                raise ValueError(\"The input feature and the tagged label dimension do not match, got %s and %s respectively.\" % (str(tuple(batch_feat.shape[:2])), str(tuple(batch_tag.shape))))\n",
        "        if batch_mask is not None:\n",
        "            if batch_feat.shape[:2] != batch_mask.shape:\n",
        "                raise ValueError(\"The input feature and the mask dimension do not match, got %s and %s respectively.\" % (str(tuple(batch_feat.shape[:2])), str(tuple(batch_mask.shape))))\n",
        "            if self.batch_first:\n",
        "                on = mask[:, 0].all()\n",
        "            else:\n",
        "                on = mask[0].all\n",
        "            if not on:\n",
        "                raise ValueError('mask of the first timestep must all be on')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3EWBkOTr--k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "62aaa1ff-9d70-4e17-dd52-08ff467dcbda"
      },
      "source": [
        "import torch\n",
        "torch.arange(5).unsqueeze(0).unsqueeze(2).shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 5, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znrKVuD5h9d-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from typing import List, Optional\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class CRF(nn.Module):\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def _viterbi_decode(self, emissions: torch.FloatTensor,\n",
        "                        mask: torch.ByteTensor) -> List[List[int]]:\n",
        "        # emissions: (seq_length, batch_size, num_tags)\n",
        "        # mask: (seq_length, batch_size)\n",
        "        assert emissions.dim() == 3 and mask.dim() == 2\n",
        "        assert emissions.shape[:2] == mask.shape\n",
        "        assert emissions.size(2) == self.num_tags\n",
        "        assert mask[0].all()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}